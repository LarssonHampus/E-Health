{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depression_prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HBKYr2LL5WT",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook we will analyze the possibility to run a machine learning algorithm for prediction of depression. The dataset can be found at http://zindi.africa/competitions/busara-mental-health-prediction-challenge. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fIKbYKSvXVE",
        "colab_type": "code",
        "outputId": "72508470-f32c-4686-cd67-bbcb3c5b8256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXHTe1Rgde1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "675dd04e-6860-4485-bfe3-a36321bef747"
      },
      "source": [
        "#import libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import xgboost as XGB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm37LqRUdl5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data \n",
        "df =  pd.read_csv('gdrive/My Drive/Colab Notebooks/Busura/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4QfjrTvMS0j",
        "colab_type": "text"
      },
      "source": [
        "We want to make sure that the data is in a suitable datatype. For example age should not be string. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddZk58lBRn_s",
        "colab_type": "code",
        "outputId": "115153a0-88a5-4d23-8950-2f9c10cb5c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.dtypes\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "surveyid                     int64\n",
              "village                      int64\n",
              "survey_date                 object\n",
              "femaleres                    int64\n",
              "age                        float64\n",
              "married                      int64\n",
              "children                     int64\n",
              "hhsize                       int64\n",
              "edu                          int64\n",
              "hh_children                  int64\n",
              "hh_totalmembers            float64\n",
              "cons_nondurable            float64\n",
              "asset_livestock            float64\n",
              "asset_durable              float64\n",
              "asset_phone                float64\n",
              "asset_savings              float64\n",
              "asset_land_owned_total     float64\n",
              "asset_niceroof               int64\n",
              "cons_allfood               float64\n",
              "cons_ownfood               float64\n",
              "cons_alcohol               float64\n",
              "cons_tobacco               float64\n",
              "cons_med_total             float64\n",
              "cons_med_children          float64\n",
              "cons_ed                    float64\n",
              "cons_social                float64\n",
              "cons_other                 float64\n",
              "ent_wagelabor                int64\n",
              "ent_ownfarm                  int64\n",
              "ent_business                 int64\n",
              "                            ...   \n",
              "med_expenses_hh_ep         float64\n",
              "med_expenses_sp_ep         float64\n",
              "med_expenses_child_ep      float64\n",
              "med_portion_sickinjured    float64\n",
              "med_port_sick_child        float64\n",
              "med_afford_port            float64\n",
              "med_sickdays_hhave         float64\n",
              "med_healthconsult          float64\n",
              "med_vacc_newborns            int64\n",
              "med_child_check              int64\n",
              "med_u5_deaths              float64\n",
              "ed_expenses                float64\n",
              "ed_expenses_perkid         float64\n",
              "ed_schoolattend            float64\n",
              "ed_sch_missedpc            float64\n",
              "ed_work_act_pc             float64\n",
              "labor_primary                int64\n",
              "wage_expenditures            int64\n",
              "durable_investment         float64\n",
              "nondurable_investment      float64\n",
              "given_mpesa                  int64\n",
              "amount_given_mpesa         float64\n",
              "received_mpesa               int64\n",
              "amount_received_mpesa      float64\n",
              "net_mpesa                  float64\n",
              "saved_mpesa                  int64\n",
              "amount_saved_mpesa         float64\n",
              "early_survey                 int64\n",
              "depressed                    int64\n",
              "day_of_week                  int64\n",
              "Length: 75, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5TwH2olMdBc",
        "colab_type": "text"
      },
      "source": [
        "As I will, for simpliity, only use the training data provided by Busura I will remove the surveyid. On their website you can upload the file and get the results for the performance of your algorithm. However, the testing dataset does not provide the labels for the target variables as does are supposed to be predicted and the evaluated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73oklxd8AkHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(columns=['surveyid'],inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIOAXyQgM7ro",
        "colab_type": "text"
      },
      "source": [
        "Encode the survey dates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7B2o5LuBG40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "df['survey_date'] = df['survey_date'].apply(lambda x: str(x))\n",
        "le.fit(df['survey_date'])\n",
        "df['survey_date'] = le.transform(df['survey_date'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_q_aF-eM_w2",
        "colab_type": "text"
      },
      "source": [
        "Determine which columns have NaN values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXd6NRINSQl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colNull = df.isnull().sum()\n",
        "colNull = [keys for keys, values in colNull.items() if values > 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc2Na8wVNE9D",
        "colab_type": "text"
      },
      "source": [
        "Using different interpolation methods to "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAUN65LJTQvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpolation_methods = ['linear','slinear', 'quadratic', 'cubic', 'polynomial', 'spline', 'piecewise_polynomial']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5P_l4PzTqIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_linear = df\n",
        "df_slinear = df\n",
        "df_quad = df\n",
        "df_cubic = df\n",
        "df_poly = df\n",
        "df_spline = df\n",
        "df_piecewise = df\n",
        "\n",
        "df_interpolation_methods = [df_linear,df_slinear,df_quad,df_cubic,df_poly,df_spline,df_piecewise]\n",
        "\n",
        "\n",
        "df_interpolation_methods = {\n",
        "\t\t\"linear\" : df,\n",
        "\t\t\"slinear\" : df,\n",
        "\t\t\"quadratic\" :df,\n",
        "\t\t\"cubic\" : df,\n",
        "    \"piecewise_polynomial\": df\n",
        "\t}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToChHsq4Sdkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for interpolation\n",
        "def interpolation(df1, method_used):\n",
        "  for i in colNull:\n",
        "    df1[i] = df1[i].interpolate(method = method_used)\n",
        "  df1.dropna(inplace=True)\n",
        "  df1.reset_index(drop=True, inplace=True)\n",
        "  return df1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZQ5_NdrNR4A",
        "colab_type": "text"
      },
      "source": [
        "We can also try to instead impute the data by using mean and median umputation methods. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJFTo1La9io-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Impute the data set. We try 3 different methods: mean, median, and knn.\n",
        "\n",
        "def perform_mean_imputation(df):\n",
        "    fill_NaN = Imputer(missing_values=np.nan, strategy='mean', axis=1)\n",
        "    imputed_DF = pd.DataFrame(fill_NaN.fit_transform(df))\n",
        "    imputed_DF.columns = df.columns\n",
        "    imputed_DF.index = df.index\n",
        "    return imputed_DF\n",
        "  \n",
        "def perform_median_imputation(df):\n",
        "    fill_NaN = Imputer(missing_values=np.nan, strategy='median', axis=1)\n",
        "    imputed_DF = pd.DataFrame(fill_NaN.fit_transform(df))\n",
        "    imputed_DF.columns = df.columns\n",
        "    imputed_DF.index = df.index \n",
        "    return imputed_DF\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63EQcRzaNW2h",
        "colab_type": "text"
      },
      "source": [
        "Begginng of the machine learning algorithm section. Now we split the dataset for training and testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WptnCNDfSPE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset(features, target):  \n",
        "  X_train, X_test, y_train, y_test = train_test_split( features, target, test_size=0.4, random_state=0)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhEHw2rMNeeh",
        "colab_type": "text"
      },
      "source": [
        "Check if the dataset is balanced. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU1Yq7iCVl6S",
        "colab_type": "code",
        "outputId": "c5d564be-1cc1-4f7c-c40d-462dff2c2351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "df['depressed'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    950\n",
              "1    193\n",
              "Name: depressed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSqkhiFLNhV8",
        "colab_type": "text"
      },
      "source": [
        "As the dataset is not balanced, we want to balance it to limit bias. We will use oversampling done by SMOTE as undersampling would result in a small dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQRgJFkmWfSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_smote(X_train,y_train):\n",
        "  sm = SMOTE(random_state=2)\n",
        "  X_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n",
        "  return X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU-bBDgWNvq5",
        "colab_type": "text"
      },
      "source": [
        "Perform interpolation for all methods as well as imputation by mean and median. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVuP_FTgXrpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key,value in df_interpolation_methods.items():\n",
        "  df_interpolation_methods[key] = interpolation(value, key)\n",
        "  \n",
        "df_interpolation_methods['Mean Imputed'] = perform_mean_imputation(df)\n",
        "df_interpolation_methods['Median Imputed'] = perform_median_imputation(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34gwGz1GN0YI",
        "colab_type": "text"
      },
      "source": [
        "For each dataframe in the dictionary we will create a test and training sample. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4fPUVMSXrrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key,value in df_interpolation_methods.items():\n",
        "  y = value['depressed']\n",
        "  X = value.drop(labels=['depressed'], axis=1)\n",
        "  X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
        "  X_train, y_train = apply_smote(X_train,y_train)\n",
        "  df_interpolation_methods[key] = [X_train, X_test, y_train, y_test]\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOjBp4zXN7iM",
        "colab_type": "text"
      },
      "source": [
        "Perform Random Forest and GradientBoosting for all dataframes in the dict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR0xfFdwXruC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ML_models(X_train, X_test, y_train, y_test):\n",
        "  model = RandomForestClassifier(random_state=3, n_estimators=20)\n",
        "  model.fit(X_train, y_train)\n",
        "  rf_pred = model.predict(X_test)\n",
        "  d = {'RandomForest':rf_pred}\n",
        "  \n",
        "  model = GradientBoostingClassifier(n_estimators=90, max_depth=3, random_state=8) \n",
        "  model.fit(X_train,y_train)\n",
        "  gb_pred = model.predict(X_test)\n",
        "  d['GradientBoosting'] = gb_pred\n",
        "  \n",
        "  return d \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVKikYmlOBmF",
        "colab_type": "text"
      },
      "source": [
        "Evaluation of the methods by confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRnbhgRbbUQx",
        "colab_type": "code",
        "outputId": "0b415472-92b7-4a5d-bd38-4b4c055732de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for key,value in df_interpolation_methods.items():\n",
        "  print('------------------------')\n",
        "  print(key)\n",
        "  [X_train, X_test, y_train, y_test] = df_interpolation_methods[key]\n",
        "  d = ML_models(X_train, X_test, y_train, y_test)\n",
        "  for key2, pred_value in d.items():\n",
        "    cm = confusion_matrix(y_test, pred_value)\n",
        "    print('----------')\n",
        "    print(key2)\n",
        "    print('True positive = ', cm[0][0])\n",
        "    print('False positive = ', cm[0][1])\n",
        "    print('False negative = ', cm[1][0])\n",
        "    print('True negative = ', cm[1][1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "linear\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n",
            "------------------------\n",
            "slinear\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n",
            "------------------------\n",
            "quadratic\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n",
            "------------------------\n",
            "cubic\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n",
            "------------------------\n",
            "piecewise_polynomial\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n",
            "------------------------\n",
            "Mean Imputed\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n",
            "------------------------\n",
            "Median Imputed\n",
            "----------\n",
            "RandomForest\n",
            "True positive =  352\n",
            "False positive =  19\n",
            "False negative =  72\n",
            "True negative =  6\n",
            "----------\n",
            "GradientBoosting\n",
            "True positive =  351\n",
            "False positive =  20\n",
            "False negative =  75\n",
            "True negative =  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8nW_3SDOGj-",
        "colab_type": "text"
      },
      "source": [
        "The work could be improved by altering and trying other machine learnign algorithms. But right not linear interpolation and RandomForest seems to work the best."
      ]
    }
  ]
}